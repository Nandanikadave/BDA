from collections import defaultdict

# Input text
text = """HDFS is a storage unit of Hadoop Mapreduce is a processing tool of Hadoop"""

# Mapper function
def mapper(text):
    mapped = []
    for line in text.strip().split("\n"):
        for word in line.strip().split():
            mapped.append((word.lower(), 1))
    return mapped

# Shuffle and sort (group by word)
def shuffle_and_sort(mapped):
    grouped = defaultdict(list)
    for word, count in mapped:
        grouped[word].append(count)
    return grouped

# Reducer function
def reducer(grouped):
    reduced = {}
    for word, counts in grouped.items():
        reduced[word] = sum(counts)
    return reduced

# Simulate MapReduce pipeline
mapped_data = mapper(text)
grouped_data = shuffle_and_sort(mapped_data)
reduced_data = reducer(grouped_data)

# Output results
print("Word count output is:\n")
for word, count in sorted(reduced_data.items()):
    print(f"{word}: {count}")
